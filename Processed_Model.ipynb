{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a395cacf",
      "metadata": {
        "id": "a395cacf"
      },
      "outputs": [],
      "source": [
        "def launch_fe(data):\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from io import StringIO\n",
        "    import json\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.impute import SimpleImputer\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "    from sklearn.feature_extraction import text\n",
        "    import pickle\n",
        "    from scipy import sparse\n",
        "    MAX_TEXT_FEATURES = 200\n",
        "    columns_list = [\"Location\", \"Hour\", \"Season\", \"Date\", \"Time\", \"Altitude\", \"Latitude\", \"Longitude\", \"YRMODAHRMI\", \"Month\", \"AmbientTemp\", \"Humidity\", \"Visibility\", \"PolyPwr\", \"Wind.Speed\", \"Pressure\", \"Cloud.Ceiling\"]\n",
        "\n",
        "    dataset = pd.read_csv(data, skipinitialspace=True)\n",
        "\n",
        "    # Replace inf and -inf, with max and min values of the particular column\n",
        "    df = dataset.select_dtypes(include=np.number)\n",
        "    cols = df.columns.to_series()[np.isinf(df).any()]\n",
        "    col_min_max = {np.inf: dataset[cols][np.isfinite(dataset[cols])].max(), -np.inf: dataset[cols][np.isfinite(dataset[cols])].min()}\n",
        "    dataset[cols] = dataset[cols].replace({col: col_min_max for col in cols})\n",
        "\n",
        "    num_samples = len(dataset)\n",
        "\n",
        "    # One hot encode categorical values\n",
        "    encode_features = [\"Location\", \"Season\"]\n",
        "    one_hot_encode_model = \\\n",
        "        OneHotEncoder(handle_unknown='ignore', sparse=False).fit(dataset[encode_features])\n",
        "    # Save the model\n",
        "    model_name = \"ed139373-2254-4c94-b084-33a55d53bdf4\"\n",
        "    fh = open(model_name, \"wb\")\n",
        "    pickle.dump(one_hot_encode_model, fh)\n",
        "    fh.close()\n",
        "\n",
        "    encode_features = [\"Location\", \"Season\"]\n",
        "    new_features = \\\n",
        "        one_hot_encode_model.transform(dataset[encode_features])\n",
        "    new_feature_names = \\\n",
        "        one_hot_encode_model.get_feature_names_out(encode_features)\n",
        "    if (sparse.issparse(new_features)):\n",
        "        new_features = new_features.toarray()\n",
        "    dataframe = pd.DataFrame(new_features, columns=new_feature_names)\n",
        "    dataset = dataset.drop(encode_features, axis=1)\n",
        "    # reset_index to re-order the index of the new dataframe.\n",
        "    dataset = pd.concat([dataset.reset_index(drop=True), dataframe.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    # Move the label column\n",
        "    cols = list(dataset.columns)\n",
        "    colIdx = dataset.columns.get_loc(\"PolyPwr\")\n",
        "    # Do nothing if the label is in the 0th position\n",
        "    # Otherwise, change the order of columns to move label to 0th position\n",
        "    if colIdx != 0:\n",
        "        cols = cols[colIdx:colIdx+1] + cols[0:colIdx] + cols[colIdx+1:]\n",
        "        dataset = dataset[cols]\n",
        "\n",
        "    # split dataset into train and test\n",
        "    train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Write train and test csv\n",
        "    train.to_csv('train.csv', index=False, header=False)\n",
        "    test.to_csv('test.csv', index=False, header=False)\n",
        "    column_names = list(train.columns)\n",
        "def get_model_id():\n",
        "    return \"ed139373-2254-4c94-b084-33a55d53bdf4\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2af9fa85",
      "metadata": {
        "id": "2af9fa85"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Upload a correct file from your local machine\n",
        "from io import BytesIO\n",
        "from google.colab import files\n",
        "uploaded_file = files.upload()\n",
        "for name in uploaded_file.keys():\n",
        "    filename = name\n",
        "data = BytesIO(uploaded_file[filename])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f52ead1",
      "metadata": {
        "id": "4f52ead1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Launch FE\n",
        "launch_fe(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a6db58a",
      "metadata": {
        "id": "7a6db58a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import the library of the algorithm\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialize hyperparams\n",
        "max_depth = None\n",
        "n_estimators = 10\n",
        "\n",
        "# Initialize the algorithm\n",
        "model = RandomForestRegressor(max_depth=max_depth, random_state=0, n_estimators=n_estimators)\n",
        "algorithm = 'RandomForestRegressor'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6f65f22",
      "metadata": {
        "id": "f6f65f22"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "# Load the test and train datasets\n",
        "train = pd.read_csv('train.csv', skipinitialspace=True, header=None)\n",
        "test = pd.read_csv('test.csv', skipinitialspace=True, header=None)\n",
        "# Train the algorithm\n",
        "model.fit(train.iloc[:,1:], train.iloc[:,0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac7c110b",
      "metadata": {
        "id": "ac7c110b"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "# Predict the target values\n",
        "y_pred = model.predict(test.iloc[:, 1:])\n",
        "# calculate rmse\n",
        "rmse = np.sqrt(np.mean((y_pred - test.iloc[:, 0])**2))\n",
        "print('RMSE of the model is: ', rmse)\n",
        "# import the library to calculate mae\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "# calculate mae\n",
        "mae = mean_absolute_error(np.array(test.iloc[:, 0]), y_pred)\n",
        "print('MAE of the model is: ', mae)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37731f23",
      "metadata": {
        "id": "37731f23"
      },
      "outputs": [],
      "source": [
        "\n",
        "# fe_transform function traansforms raw data into a form the model can consume\n",
        "print('Below is the prediction stage of the AI')\n",
        "def fe_transform(data_dict, object_path=None):\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    from io import StringIO\n",
        "    import json\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.impute import SimpleImputer\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "    from sklearn.feature_extraction import text\n",
        "    import pickle\n",
        "    from scipy import sparse\n",
        "\n",
        "    dataset = pd.DataFrame([data_dict])\n",
        "\n",
        "    encode_features = [\"Location\", \"Season\"]\n",
        "    object_name = \"ed139373-2254-4c94-b084-33a55d53bdf4\"\n",
        "    file_name = open(object_name, 'rb')\n",
        "    one_hot_encode_model = pickle.load(file_name)\n",
        "    new_features = \\\n",
        "        one_hot_encode_model.transform(dataset[encode_features])\n",
        "    new_feature_names = \\\n",
        "        one_hot_encode_model.get_feature_names_out(encode_features)\n",
        "    if (sparse.issparse(new_features)):\n",
        "        new_features = new_features.toarray()\n",
        "    dataframe = pd.DataFrame(new_features, columns=new_feature_names)\n",
        "    dataset = dataset.drop(encode_features, axis=1)\n",
        "    # reset_index to re-order the index of the new dataframe.\n",
        "    dataset = pd.concat([dataset.reset_index(drop=True), dataframe.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bccebf6b",
      "metadata": {
        "id": "bccebf6b"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_sample = {'Location': 'Travis', 'Date': 20175763.5, 'Time': 1272.5, 'Altitude': 974.0, 'Latitude': 34.205, 'Longitude': -118.275, 'Hour': 13, 'YRMODAHRMI': 201757500000.0, 'Month': 6.5, 'AmbientTemp': 22.878300000000003, 'Season': 'Summer', 'Humidity': 49.993895, 'Visibility': 5.0, 'Wind.Speed': 24.5, 'Pressure': 905.6, 'Cloud.Ceiling': 361.0}\n",
        "# Call FE on test_sample\n",
        "test_sample_modified = fe_transform(test_sample)\n",
        "# Make a prediction\n",
        "prediction = model.predict(test_sample_modified)\n",
        "print(prediction)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
